#!/usr/bin/env python

import argparse
import html2text # for converting to readable text
import urllib2 #for grabbing html from page

class TagExtractor:
	
	toc = None
	tags = []
	html = None

	def __init__(self,html):
		self.html = str(html)
	def extractToc(self):
		parse_point1 = "<div id=" + '"' + "toc" + '"' + " class=" + '"' + "toc" + '"' + ">"
		#parse_point1 = "<div id ="
		parse_point2 = "<p>"

		i = self.html.find(parse_point1,0)
		j = self.html.find(parse_point2,i) 

		print(i,j)
		self.toc = self.html[i:j]	
		return self.html[i:j]

parser = argparse.ArgumentParser()
parser.add_argument("wikipage")
#optional argument
parser.add_argument("--ignorelinks", help = "ignores the links", action = "store_true")
parser.add_argument("--fullpage", help = "prints full page instead of just TOC", action = "store_true")
args = parser.parse_args()

page = args.wikipage.replace(" ","_")
language = "en"

query_string = "https://" + language + ".wikipedia.org/wiki/" + page
print(query_string)
#this just grabs all the html at once
page_response = urllib2.urlopen(query_string)

page_html = page_response.read()

extract = TagExtractor(page_html)
toc_html = extract.extractToc()

conv = html2text.HTML2Text()
#if(args.ignorelinks):
#conv.ignore_links = True

page_text = conv.handle(page_html.decode('utf8'))
toc_text = conv.handle(toc_html.decode('utf8'))
with open("html.txt","w") as f:
	f.write(page_html)

print(toc_text)


